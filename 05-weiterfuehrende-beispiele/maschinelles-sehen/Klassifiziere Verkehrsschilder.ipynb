{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifiziere Verkehrsschilder\n",
    "\n",
    "In diesem Jupyter Notebook geht es um die Erkennung von Verkehrszeichen.\n",
    "Der dafür verwendete Datensatz ist der German Traffic Sign Recognition Benchmark, kurz GTSRB.\n",
    "Sämtliche Informationen rund um den Datensatz sind [online](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) einsehbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import imageio.v2 as imageio\n",
    "import skimage.transform\n",
    "import skimage.feature\n",
    "import skimage.color\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import gtsrb_db_loader  # hierbei handelt es sich um ein selbstgeschriebenes Modul in gleichen Ordner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem Code-Schnippsel wird die ZIP-Datei automatisch heruntergeladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import shutil\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "file_name = \"GTSRB_Final_Training_Images.zip\"\n",
    "if file_name not in os.listdir(\".\"):\n",
    "    url = \"https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip\"\n",
    "    r = requests.get(url, stream=True, allow_redirects=True)\n",
    "    if r.status_code != 200:\n",
    "        r.raise_for_status()\n",
    "        raise RuntimeError(f\"Request to {url} returned status code {r.status_code}\")\n",
    "    file_size = int(r.headers.get('Content-Length', 0))\n",
    "    desc = \"(Unknown total file size)\" if file_size == 0 else \"\"\n",
    "    r.raw.read = functools.partial(r.raw.read, decode_content=True)\n",
    "    with tqdm.wrapattr(r.raw, \"read\", total=file_size, desc=desc) as r_raw:\n",
    "        with open(file_name, \"wb\") as f:\n",
    "            shutil.copyfileobj(r_raw, f)\n",
    "else:\n",
    "    print(f\"Datei '{file_name}' ist bereits heruntergeladen\")\n",
    "\n",
    "print(\"Inhalt des Ordners:\")\n",
    "for file_entry in os.listdir(\".\"):\n",
    "    print(\"- \", file_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird die ZIP-Datei in den Unterordner `GTSRB_Final_Training_Images` entpackt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "folder_name = \"GTSRB_Final_Training_Images\"\n",
    "\n",
    "if folder_name not in os.listdir(\".\"):\n",
    "    with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"GTSRB_Final_Training_Images\")\n",
    "else:\n",
    "    print(\"Ziel-Ordner fürs Entpacken existiert bereits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können statt der vorherigen zwei Code-Zellen auch einfach das ZIP-Archiv von\n",
    "[hier](https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip)\n",
    "herunterladen und im gleichen Ordner wie das Jupyter Notebook entpacken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legen Sie das Verzeichnis `GTSRB` in das gleiche Verzeichnis wie das Notebook.\n",
    "Falls das Kopieren zu viel Zeit benötigt, passen Sie `path_to_directory` so an, dass der Pfad auf den entpackten Ordner mit den Verkehrsschildern zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_directory = \"./GTSRB_Final_Training_Images\"\n",
    "\n",
    "df = gtsrb_db_loader.load_traffic_sign_database(path_to_directory)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for row in gtsrb_db_loader.log_progress(df.itertuples(), size=len(df)):\n",
    "    color_image = imageio.imread(row.path_to_image).astype(int, copy=False)\n",
    "    gray_image = skimage.color.rgb2gray(color_image)\n",
    "    cropped_image = gray_image[row.Roi_Y1:row.Roi_Y2, row.Roi_X1:row.Roi_X2]\n",
    "    resized_image = skimage.transform.resize(cropped_image, [40, 40], mode=\"constant\")\n",
    "    images.append(resized_image)\n",
    "df = df.assign(image=images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Verkehrsschild sieht nun so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = df.iloc[0].image\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe von Histograms of Gradients (HOGs) können Gegenstände gut automatisiert klassifiziert werden.\n",
    "Diese werden z. B. im Artikel\n",
    "[\"Histograms of Oriented Gradients for Human Detection\" von N. Dalal und B. Triggs](https://hal.inria.fr/docs/00/54/85/12/PDF/hog_cvpr2005.pdf)\n",
    "gut beschrieben.\n",
    "Die HOGs des oben gezeigte Beispielbild werden im Folgenden angezeigt.\n",
    "\n",
    "Eine einfache Möglichkeit, Bilder in HOGs umzuwandeln, wird von\n",
    "[scikit-image](http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog)\n",
    "bereitgestellt und im Folgenden verwendet.\n",
    "\n",
    "Zunächst wird für das obige Verkehrszeichen gezeigt, wie die HOG-Repräsentation aussieht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_img = skimage.feature.hog(\n",
    "    sample_image,\n",
    "    transform_sqrt=True,\n",
    "    orientations=8,\n",
    "    pixels_per_cell=(6, 6),\n",
    "    cells_per_block=(3, 3),\n",
    "    feature_vector=True,\n",
    "    block_norm=\"L2-Hys\",\n",
    "    visualize=True\n",
    ")[1]\n",
    "plt.imshow(hog_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features = []\n",
    "for row in gtsrb_db_loader.log_progress(df.itertuples(), size=len(df)):\n",
    "    hog_feature = skimage.feature.hog(\n",
    "        row.image,\n",
    "        transform_sqrt=True,\n",
    "        orientations=8,   # es gibt 8 verschiedene Kanten-Gruppen\n",
    "        pixels_per_cell=(6, 6),\n",
    "        cells_per_block=(3, 3),\n",
    "        feature_vector=True,\n",
    "        block_norm=\"L2-Hys\",\n",
    "        visualize=False\n",
    "    )\n",
    "    hog_features.append(hog_feature)\n",
    "df = df.assign(hog_feature=hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind die Daten soweit vorbereitet, dass der Zusammenhang zwischen dem Bild und dem Verkehrszeichen durch eine geeignete Methode des ML hergestellt werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[\"hog_feature\"].values\n",
    "targets = df[\"ClassId\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noch eine Kleinigkeit:\n",
    "Die HOGs liegen als Arrays von Arrays vor, der Lernalgorithmus benötigt aber ein einzelnes langes Array.\n",
    "Dafür müssen die Arrays aneinander gehängt werden.\n",
    "Dies kann einfach durch[`np.stack`](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.stack.html) vorgenommen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Klassifizierungs-Algorithmus wird ein Random Forest (RF) eingesetzt.\n",
    "Der Random Forest ist ein Ensemble von mehreren Entscheidungsbäumen.\n",
    "Im Folgenden wird eine [Implementierung von scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) eingesetzt.\n",
    "\n",
    "Für die Bewertung der Ergebnisse können nun verschiedene Aspekte betrachtet werden.\n",
    "Die Accuracy ist ein einfaches Maß, um den Anteil der richtig bestimmten Klassen zu quantifizieren.\n",
    "Die Confusion Matrix ermöglicht es, zu sehen, welche Klassen miteinander verwechselt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=7,\n",
    "    n_jobs=-1,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=None\n",
    ")\n",
    "random_forest.fit(X_train, y_train)\n",
    "score = random_forest.score(X_test, y_test)\n",
    "print(f\"Genauigkeit (Accurarcy): {score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine schöne Möglichkeit, eine Confusion Matrix zu visualisieren, ist, diese als Bild zu plotten.\n",
    "Der folgende Code ist der \n",
    "[Dokumentation von scikit-learn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)\n",
    "entnommen und angepasst worden.\n",
    "Die Verkehrsschilder (als Liste in der Variablen `classes`) werden durch die Zahlen 0 bis 42 repräsentiert. Dies entspricht den Klassennamen aus der Vorlesung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "matrix = ConfusionMatrixDisplay.from_estimator(random_forest, X_test, y_test, include_values=True, cmap=\"BuPu\", ax=ax)\n",
    "ax.images[-1].colorbar.remove()\n",
    "plt.colorbar(matrix.im_, shrink=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier kann man nun sehen, welche Verkehrszeichen besonders häufig miteinander verwechselt werden.\n",
    "Der Schlüssel, welche Klassen-ID welchem Schild entspricht, ist in den Vorlesungsunterlagen enthalten.\n",
    "Der Einfachkeit halber ist hier aber auch ein Suchtool hinterlegt.\n",
    "Klicken Sie auf den Button `Suche nach Schild`, um nach dem Schild mit der ausgewählten `class_id` zu suchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def plot_sample_for_class_id(class_id):\n",
    "    display(Markdown(f\"### Beispielbilder für ID {class_id}\"))\n",
    "    ncols = 3\n",
    "    nrows = 7\n",
    "    _, axs = plt.subplots(ncols, nrows, figsize=(12, 5))\n",
    "    for j in range(ncols):\n",
    "        ax = axs[j]\n",
    "        for i in range(nrows):\n",
    "            sample_image_for_class_id = df[df.ClassId == class_id].sample(n=1).iloc[0]\n",
    "            ax[i].imshow(sample_image_for_class_id.image, cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    display(Markdown(f\"### Erster Eintrag für ID {class_id}\"))\n",
    "    display(df[df.ClassId == class_id].iloc[0])\n",
    "\n",
    "\n",
    "widgets.interactive(\n",
    "    plot_sample_for_class_id,\n",
    "    {\n",
    "        'manual': True,\n",
    "        'manual_name': \"Suche nach Schild\"\n",
    "    },\n",
    "    class_id=(0, 42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Dieser Datensatz ist bereits häufiger in [wissenschaftlichen Veröffentlichungen](http://benchmark.ini.rub.de/?section=gtsrb&subsection=results) referenziert worden.\n",
    "Besonders zu empfehlen ist der Artikel \"Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition\" von J. Stallkamp, M. Schlipsing, J. Salmena und C. Igel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0; display:inline\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a> &nbsp;&nbsp;&nbsp;&nbsp;Dieses Werk von Marvin Kastner ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Namensnennung 4.0 International Lizenz</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
